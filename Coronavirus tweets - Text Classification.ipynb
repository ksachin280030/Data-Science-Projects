{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5bba9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer2 = PorterStemmer()\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer3 = LancasterStemmer()\n",
    "import string\n",
    "punct = string.punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a67bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = pd.read_csv(\"C:/mini project/Coronavirus tweets - Text Classification/Corona_NLP_train.csv\", encoding=\"latin1\")\n",
    "test_tweets = pd.read_csv(\"C:/mini project/Coronavirus tweets - Text Classification/Corona_NLP_test.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "887da36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "361142da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets.drop([\"UserName\" , \"ScreenName\" , \"Location\"] , axis = 1 , inplace = True)\n",
    "test_tweets.drop([\"UserName\" , \"ScreenName\" , \"Location\"], axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda42335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41157 entries, 0 to 41156\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   TweetAt        41157 non-null  object\n",
      " 1   OriginalTweet  41157 non-null  object\n",
      " 2   Sentiment      41157 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 964.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3798 entries, 0 to 3797\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   TweetAt        3798 non-null   object\n",
      " 1   OriginalTweet  3798 non-null   object\n",
      " 2   Sentiment      3798 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 89.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_tweets.info())\n",
    "print(test_tweets.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "025bddb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive              11422\n",
       "Negative               9917\n",
       "Neutral                7713\n",
       "Extremely Positive     6624\n",
       "Extremely Negative     5481\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets[\"Sentiment\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a89a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OrdinalEncoder\n",
    "maplist = [{'col': 'Sentiment', 'mapping': {'Extremely Negative': 0, 'Negative': 1,'Neutral': 2, 'Positive': 3, 'Extremely Positive': 4}}]\n",
    "enc = OrdinalEncoder(mapping=maplist)\n",
    "train_tweets = enc.fit_transform(train_tweets)\n",
    "test_tweets = enc.transform(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4251f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = train_tweets[\"Sentiment\"]\n",
    "Ytest = test_tweets[\"Sentiment\"]\n",
    "Xtrain = train_tweets.drop(\"Sentiment\" , axis = 1)\n",
    "Xtest = test_tweets.drop(\"Sentiment\" , axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e02b1b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TweetAt                                      OriginalTweet\n",
       "0      16-03-2020  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...\n",
       "1      16-03-2020  advice Talk to your neighbours family to excha...\n",
       "2      16-03-2020  Coronavirus Australia: Woolworths to give elde...\n",
       "3      16-03-2020  My food stock is not the only one which is emp...\n",
       "4      16-03-2020  Me, ready to go at supermarket during the #COV...\n",
       "...           ...                                                ...\n",
       "41152  14-04-2020  Airline pilots offering to stock supermarket s...\n",
       "41153  14-04-2020  Response to complaint not provided citing COVI...\n",
       "41154  14-04-2020  You know itÂs getting tough when @KameronWild...\n",
       "41155  14-04-2020  Is it wrong that the smell of hand sanitizer i...\n",
       "41156  14-04-2020  @TartiiCat Well new/used Rift S are going for ...\n",
       "\n",
       "[41157 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2bf9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "765fd35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>13</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>13</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>13</td>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>13</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>13</td>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TweetAt                                      OriginalTweet\n",
       "0           14  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...\n",
       "1           14  advice Talk to your neighbours family to excha...\n",
       "2           14  Coronavirus Australia: Woolworths to give elde...\n",
       "3           14  My food stock is not the only one which is emp...\n",
       "4           14  Me, ready to go at supermarket during the #COV...\n",
       "...        ...                                                ...\n",
       "41152       13  Airline pilots offering to stock supermarket s...\n",
       "41153       13  Response to complaint not provided citing COVI...\n",
       "41154       13  You know itÂs getting tough when @KameronWild...\n",
       "41155       13  Is it wrong that the smell of hand sanitizer i...\n",
       "41156       13  @TartiiCat Well new/used Rift S are going for ...\n",
       "\n",
       "[41157 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode labels in column 'species'.\n",
    "Xtrain['TweetAt']= label_encoder.fit_transform(Xtrain['TweetAt'])\n",
    "Xtest['TweetAt']= label_encoder.fit_transform(Xtest['TweetAt'])\n",
    "Xtrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ada3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= stopwords.words(\"english\")\n",
    "stop_words.remove(\"very\")\n",
    "stop_words.remove( \"so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fcc629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(tweet) : \n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "    tweet = re.sub(\"@[A-Za-z0-9_]+\",\"\", tweet)\n",
    "    for p in punct :\n",
    "        while(str(p) in tweet ) :\n",
    "            tweet = tweet.replace(p , \"\")\n",
    "    tweet = word_tokenize(tweet)\n",
    "    tweet = [w for w in tweet if (w not in stop_words )]\n",
    "    entier= ['0','1','2','3','4','5','6','7','8','9']\n",
    "    \n",
    "    tweet2 = tweet.copy()\n",
    "    for i in tweet2 : \n",
    "        for j in i : \n",
    "            if j in entier : \n",
    "                tweet.remove(i)\n",
    "                break\n",
    "\n",
    "    #tweet = [stemmer.stem(w) for w in tweet]\n",
    "    tweet =\" \".join(tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "301ea6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "480f7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "bow_train = vectorizer.fit_transform(Xtrain[\"OriginalTweet\"])\n",
    "features = vectorizer.get_feature_names_out()\n",
    "Xtrain_bow=pd.DataFrame(bow_train.toarray(), columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6373d9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00pm</th>\n",
       "      <th>03</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10am</th>\n",
       "      <th>...</th>\n",
       "      <th>youâ</th>\n",
       "      <th>yoy</th>\n",
       "      <th>yr</th>\n",
       "      <th>yâ</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3798 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  00pm  03  08  09  10  100  1000  10am  ...  youâ  yoy  yr  yâ  \\\n",
       "0      0    0     0   0   0   0   0    0     0     0  ...     0    0   0   0   \n",
       "1      0    0     0   0   0   0   0    0     0     0  ...     0    0   0   0   \n",
       "2      0    0     0   0   0   0   0    0     0     0  ...     0    0   0   0   \n",
       "3      0    0     0   0   0   0   0    0     0     0  ...     0    0   0   0   \n",
       "4      0    0     0   0   0   0   0    0     0     0  ...     0    0   0   0   \n",
       "...   ..  ...   ...  ..  ..  ..  ..  ...   ...   ...  ...   ...  ...  ..  ..   \n",
       "3793   0    0     0   0   0   0   0    0     0     0  ...     0    0   0   0   \n",
       "3794   0    0     0   0   0   0   0    0     0     0  ...     0    0   0   0   \n",
       "3795   0    0     0   0   0   0   0    0     0     0  ...     0    0   0   0   \n",
       "3796   0    0     0   0   0   0   0    0     0     0  ...     0    0   0   0   \n",
       "3797   0    0     0   0   0   0   0    0     0     0  ...     0    0   0   0   \n",
       "\n",
       "      zealand  zero  zimbabwe  zombie  zone  zoom  \n",
       "0           0     0         0       0     0     0  \n",
       "1           0     0         0       0     0     0  \n",
       "2           0     0         0       0     0     0  \n",
       "3           0     0         0       0     0     0  \n",
       "4           0     0         0       0     0     0  \n",
       "...       ...   ...       ...     ...   ...   ...  \n",
       "3793        0     0         0       0     0     0  \n",
       "3794        0     0         0       0     0     0  \n",
       "3795        0     0         0       0     0     0  \n",
       "3796        0     0         0       0     0     0  \n",
       "3797        0     0         0       0     0     0  \n",
       "\n",
       "[3798 rows x 5000 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_test = vectorizer.transform(Xtest[\"OriginalTweet\"])\n",
    "Xtest_bow=pd.DataFrame(bow_test.toarray(), columns = features)\n",
    "Xtest_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87054350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    40884\n",
       "1      265\n",
       "2        8\n",
       "Name: love, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_bow[\"love\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c80ef8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_bow  = pd.concat([Xtrain[\"TweetAt\"], Xtrain_bow] , axis =1)\n",
    "Xtest_bow  = pd.concat([Xtest[\"TweetAt\"], Xtest_bow] , axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efb3af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13b5de17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.63      5481\n",
      "           1       0.57      0.50      0.53      9917\n",
      "           2       0.55      0.71      0.62      7713\n",
      "           3       0.59      0.47      0.52     11422\n",
      "           4       0.60      0.67      0.63      6624\n",
      "\n",
      "    accuracy                           0.58     41157\n",
      "   macro avg       0.58      0.60      0.59     41157\n",
      "weighted avg       0.58      0.58      0.58     41157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#naive bayes\n",
    "nb.fit(Xtrain_bow, Ytrain)\n",
    "ypred_tr = nb.predict(Xtrain_bow)\n",
    "ypred_ts = nb.predict(Xtest_bow)\n",
    "print(\"Training Results:\\n\")\n",
    "print(classification_report(Ytrain, ypred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58e4258a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.61      0.52       592\n",
      "           1       0.47      0.40      0.43      1041\n",
      "           2       0.58      0.61      0.59       619\n",
      "           3       0.46      0.41      0.43       947\n",
      "           4       0.54      0.57      0.55       599\n",
      "\n",
      "    accuracy                           0.50      3798\n",
      "   macro avg       0.50      0.52      0.51      3798\n",
      "weighted avg       0.49      0.50      0.49      3798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Results:\\n\")\n",
    "ypred_ts = nb.predict(Xtest_bow)\n",
    "print(classification_report(Ytest, ypred_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8dd2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 20000\n",
    "max_length = 60\n",
    "embedding_dim = 64\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "\n",
    "# Initialize the Tokenizer class\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "\n",
    "# Generate the word index dictionary for the training sentences\n",
    "tokenizer.fit_on_texts(Xtrain[\"OriginalTweet\"])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Generate and pad the training sequences\n",
    "sequences = tokenizer.texts_to_sequences(Xtrain[\"OriginalTweet\"])\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "# Generate and pad the test sequences\n",
    "testing_sequences = tokenizer.texts_to_sequences(Xtest[\"OriginalTweet\"])\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d9b70dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53069055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 60, 64)            1280000   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3840)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3840)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                61456     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,341,541\n",
      "Trainable params: 1,341,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, 64, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Setup the training parameters\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9ef9eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1287/1287 [==============================] - 37s 27ms/step - loss: 1.2760 - accuracy: 0.4435 - val_loss: 1.0525 - val_accuracy: 0.5811\n",
      "Epoch 2/30\n",
      "1287/1287 [==============================] - 36s 28ms/step - loss: 0.8015 - accuracy: 0.6936 - val_loss: 0.9402 - val_accuracy: 0.6348\n",
      "Epoch 3/30\n",
      "1287/1287 [==============================] - 35s 27ms/step - loss: 0.5621 - accuracy: 0.7978 - val_loss: 0.9950 - val_accuracy: 0.6393\n",
      "Epoch 4/30\n",
      "1287/1287 [==============================] - 36s 28ms/step - loss: 0.3983 - accuracy: 0.8629 - val_loss: 1.0378 - val_accuracy: 0.6382\n",
      "Epoch 5/30\n",
      "1287/1287 [==============================] - 36s 28ms/step - loss: 0.2977 - accuracy: 0.8953 - val_loss: 1.1193 - val_accuracy: 0.6316\n",
      "Epoch 6/30\n",
      "1287/1287 [==============================] - 43s 33ms/step - loss: 0.2362 - accuracy: 0.9179 - val_loss: 1.2744 - val_accuracy: 0.6209\n",
      "Epoch 7/30\n",
      "1287/1287 [==============================] - 42s 33ms/step - loss: 0.1948 - accuracy: 0.9311 - val_loss: 1.3298 - val_accuracy: 0.6132\n",
      "Epoch 8/30\n",
      "1287/1287 [==============================] - 36s 28ms/step - loss: 0.1719 - accuracy: 0.9400 - val_loss: 1.3481 - val_accuracy: 0.6080\n",
      "Epoch 9/30\n",
      "1287/1287 [==============================] - 35s 27ms/step - loss: 0.1565 - accuracy: 0.9436 - val_loss: 1.4767 - val_accuracy: 0.6064\n",
      "Epoch 10/30\n",
      "1287/1287 [==============================] - 45s 35ms/step - loss: 0.1415 - accuracy: 0.9499 - val_loss: 1.5301 - val_accuracy: 0.6051\n",
      "Epoch 11/30\n",
      "1287/1287 [==============================] - 48s 37ms/step - loss: 0.1291 - accuracy: 0.9554 - val_loss: 1.6284 - val_accuracy: 0.6190\n",
      "Epoch 12/30\n",
      "1287/1287 [==============================] - 47s 37ms/step - loss: 0.1199 - accuracy: 0.9579 - val_loss: 1.6182 - val_accuracy: 0.5993\n",
      "Epoch 13/30\n",
      "1287/1287 [==============================] - 46s 36ms/step - loss: 0.1153 - accuracy: 0.9596 - val_loss: 1.7184 - val_accuracy: 0.6014\n",
      "Epoch 14/30\n",
      "1287/1287 [==============================] - 43s 33ms/step - loss: 0.1085 - accuracy: 0.9621 - val_loss: 1.7669 - val_accuracy: 0.5948\n",
      "Epoch 15/30\n",
      "1287/1287 [==============================] - 40s 31ms/step - loss: 0.1033 - accuracy: 0.9638 - val_loss: 1.7287 - val_accuracy: 0.6016\n",
      "Epoch 16/30\n",
      "1287/1287 [==============================] - 40s 31ms/step - loss: 0.0944 - accuracy: 0.9674 - val_loss: 1.7030 - val_accuracy: 0.6058\n",
      "Epoch 17/30\n",
      "1287/1287 [==============================] - 34s 26ms/step - loss: 0.0922 - accuracy: 0.9678 - val_loss: 1.8271 - val_accuracy: 0.6048\n",
      "Epoch 18/30\n",
      "1287/1287 [==============================] - 32s 25ms/step - loss: 0.0875 - accuracy: 0.9689 - val_loss: 1.7800 - val_accuracy: 0.6093\n",
      "Epoch 19/30\n",
      "1287/1287 [==============================] - 31s 24ms/step - loss: 0.0816 - accuracy: 0.9719 - val_loss: 1.8096 - val_accuracy: 0.6077\n",
      "Epoch 20/30\n",
      "1287/1287 [==============================] - 31s 24ms/step - loss: 0.0774 - accuracy: 0.9730 - val_loss: 1.8428 - val_accuracy: 0.6035\n",
      "Epoch 21/30\n",
      "1287/1287 [==============================] - 32s 25ms/step - loss: 0.0784 - accuracy: 0.9722 - val_loss: 1.9722 - val_accuracy: 0.5948\n",
      "Epoch 22/30\n",
      "1287/1287 [==============================] - 33s 26ms/step - loss: 0.0749 - accuracy: 0.9749 - val_loss: 1.8582 - val_accuracy: 0.6043\n",
      "Epoch 23/30\n",
      "1287/1287 [==============================] - 36s 28ms/step - loss: 0.0709 - accuracy: 0.9748 - val_loss: 1.9225 - val_accuracy: 0.5987\n",
      "Epoch 24/30\n",
      "1287/1287 [==============================] - 31s 24ms/step - loss: 0.0744 - accuracy: 0.9746 - val_loss: 1.9054 - val_accuracy: 0.5995\n",
      "Epoch 25/30\n",
      "1287/1287 [==============================] - 32s 25ms/step - loss: 0.0683 - accuracy: 0.9754 - val_loss: 2.0455 - val_accuracy: 0.5948\n",
      "Epoch 26/30\n",
      "1287/1287 [==============================] - 32s 25ms/step - loss: 0.0678 - accuracy: 0.9769 - val_loss: 1.9292 - val_accuracy: 0.6024\n",
      "Epoch 27/30\n",
      "1287/1287 [==============================] - 31s 24ms/step - loss: 0.0615 - accuracy: 0.9782 - val_loss: 2.0901 - val_accuracy: 0.5911\n",
      "Epoch 28/30\n",
      "1287/1287 [==============================] - 31s 24ms/step - loss: 0.0629 - accuracy: 0.9788 - val_loss: 2.0081 - val_accuracy: 0.6001\n",
      "Epoch 29/30\n",
      "1287/1287 [==============================] - 31s 24ms/step - loss: 0.0593 - accuracy: 0.9795 - val_loss: 1.9648 - val_accuracy: 0.6024\n",
      "Epoch 30/30\n",
      "1287/1287 [==============================] - 32s 25ms/step - loss: 0.0559 - accuracy: 0.9814 - val_loss: 2.0516 - val_accuracy: 0.6006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2648bf999d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded, Ytrain, epochs=num_epochs, validation_data=(testing_padded, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a498568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 60, 64)            1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 60, 64)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,346,373\n",
      "Trainable params: 1,346,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#lstm\n",
    "embedding_vector_features=64\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Embedding, LSTM , Dense\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size,embedding_vector_features,input_length=max_length))\n",
    "\n",
    "model.add(LSTM(64,activation='relu',return_sequences=True))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(LSTM(64,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcb826dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1287/1287 [==============================] - 121s 90ms/step - loss: 1.3070 - accuracy: 0.4379 - val_loss: 0.9473 - val_accuracy: 0.6216\n",
      "Epoch 2/20\n",
      "1287/1287 [==============================] - 112s 87ms/step - loss: 0.9856 - accuracy: 0.6860 - val_loss: 0.7831 - val_accuracy: 0.7180\n",
      "Epoch 3/20\n",
      "1287/1287 [==============================] - 113s 88ms/step - loss: 0.6103 - accuracy: 0.7937 - val_loss: 0.7139 - val_accuracy: 0.7522\n",
      "Epoch 4/20\n",
      "1287/1287 [==============================] - 117s 91ms/step - loss: 0.5188 - accuracy: 0.8295 - val_loss: 0.7349 - val_accuracy: 0.7504\n",
      "Epoch 5/20\n",
      "1287/1287 [==============================] - 117s 91ms/step - loss: 0.4554 - accuracy: 0.8502 - val_loss: 0.7378 - val_accuracy: 0.7464\n",
      "Epoch 6/20\n",
      "1287/1287 [==============================] - 115s 89ms/step - loss: 0.4313 - accuracy: 0.8601 - val_loss: 0.7459 - val_accuracy: 0.7617\n",
      "Epoch 7/20\n",
      "1287/1287 [==============================] - 117s 91ms/step - loss: 0.4460 - accuracy: 0.8652 - val_loss: 0.8181 - val_accuracy: 0.7554\n",
      "Epoch 8/20\n",
      "1287/1287 [==============================] - 119s 93ms/step - loss: 0.2994 - accuracy: 0.9027 - val_loss: 0.8720 - val_accuracy: 0.7567\n",
      "Epoch 9/20\n",
      "1287/1287 [==============================] - 116s 90ms/step - loss: 0.2451 - accuracy: 0.9193 - val_loss: 0.9917 - val_accuracy: 0.7438\n",
      "Epoch 10/20\n",
      "1287/1287 [==============================] - 114s 88ms/step - loss: 0.2147 - accuracy: 0.9306 - val_loss: 1.0297 - val_accuracy: 0.7454\n",
      "Epoch 11/20\n",
      "1287/1287 [==============================] - 113s 87ms/step - loss: 0.1977 - accuracy: 0.9382 - val_loss: 1.0726 - val_accuracy: 0.7567\n",
      "Epoch 12/20\n",
      "1287/1287 [==============================] - 115s 89ms/step - loss: 0.1626 - accuracy: 0.9479 - val_loss: 1.1866 - val_accuracy: 0.7435\n",
      "Epoch 13/20\n",
      "1287/1287 [==============================] - 113s 88ms/step - loss: 0.1399 - accuracy: 0.9553 - val_loss: 1.1724 - val_accuracy: 0.7467\n",
      "Epoch 14/20\n",
      "1287/1287 [==============================] - 114s 88ms/step - loss: 0.1228 - accuracy: 0.9605 - val_loss: 1.3249 - val_accuracy: 0.7422\n",
      "Epoch 15/20\n",
      "1287/1287 [==============================] - 114s 89ms/step - loss: 0.1186 - accuracy: 0.9625 - val_loss: 1.2365 - val_accuracy: 0.7409\n",
      "Epoch 16/20\n",
      "1287/1287 [==============================] - 111s 86ms/step - loss: 0.1004 - accuracy: 0.9686 - val_loss: 1.4501 - val_accuracy: 0.7475\n",
      "Epoch 17/20\n",
      "1287/1287 [==============================] - 112s 87ms/step - loss: 0.0823 - accuracy: 0.9755 - val_loss: 1.5165 - val_accuracy: 0.7404\n",
      "Epoch 18/20\n",
      "1287/1287 [==============================] - 113s 88ms/step - loss: 0.0826 - accuracy: 0.9754 - val_loss: 1.5184 - val_accuracy: 0.7364\n",
      "Epoch 19/20\n",
      "1287/1287 [==============================] - 113s 88ms/step - loss: 0.0670 - accuracy: 0.9790 - val_loss: 1.6918 - val_accuracy: 0.7383\n",
      "Epoch 20/20\n",
      "1287/1287 [==============================] - 112s 87ms/step - loss: 0.0567 - accuracy: 0.9831 - val_loss: 2.1111 - val_accuracy: 0.7338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x264a4bd59a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, Ytrain, epochs=20, validation_data=(testing_padded, Ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2e5d754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sachin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import nltk\n",
    ">>> nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "504d2b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_test = tokenizer.texts_to_sequences(np.array([process(\" i am happy\")  ]))\n",
    "testing_tweet = pad_sequences(to_test,maxlen=max_length, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9124eeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 595ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.6074633e-09, 1.7133463e-05, 2.6345463e-03, 9.9311793e-01,\n",
       "        4.2303759e-03]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(testing_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c333e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
